{'beta_categorical': 1.0, 'beta_hinge': 1.0, 'beta_lqp': 1.0, 'beta_multiplier': 1.5, 'beta_threshold': 1.0, 'clamp': True, 'class_weights': 100, 'convergence_tolerance': 2e-06, 'feature_types': ['linear', 'hinge', 'product'], 'n_cpus': 2, 'n_hinge_features': 10, 'n_lambdas': 100, 'n_threshold_features': 10, 'scorer': 'roc_auc', 'tau': 0.5, 'transform': 'cloglog', 'use_lambdas': 'best', 'use_sklearn': True}
Training AUC score: 0.973
{'feature_types': ['linear', 'hinge', 'product'], 'tau': 0.5, 'transform': 'cloglog', 'clamp': True, 'scorer': 'roc_auc', 'beta_multiplier': 1.5, 'beta_hinge': 1.0, 'beta_lqp': 1.0, 'beta_threshold': 1.0, 'beta_categorical': 1.0, 'n_hinge_features': 10, 'n_threshold_features': 10, 'convergence_tolerance': 2e-06, 'n_cpus': 2, 'use_lambdas': 'best', 'n_lambdas': 100, 'class_weights': 100, 'use_sklearn': True, 'initialized_': True, 'estimator': LogisticRegression(C=2.574433833577736, penalty='l1', solver='liblinear',
                   tol=2e-06), 'preprocessor': None, 'transformer': MaxentFeatureTransformer(), 'regularization_': None, 'lambdas_': None, 'beta_scores_': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.54279117e+00,
        0.00000000e+00,  2.44493765e+01,  0.00000000e+00, -4.31890817e-01,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.32501342e+01,
        1.55029024e+01,  0.00000000e+00, -3.32534737e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  5.34167281e-01,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00, -4.54368682e-01,  0.00000000e+00,
       -9.96827738e-01,  0.00000000e+00, -6.46095359e+00,  0.00000000e+00,
        0.00000000e+00,  1.92793361e+00,  2.08306560e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -6.90224529e+00,
        0.00000000e+00, -1.50054513e+01,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
       -5.34649537e-04,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.01426881e+01,
        1.22870090e+01,  2.71963703e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00, -5.05422970e+00, -5.59616491e+00,
       -1.67898564e+00, -5.00431413e-01,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00, -1.72198539e+01, -7.62635077e+00,  4.01316800e+00,
        7.56065879e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
       -2.34219572e+01, -7.50197961e-01,  0.00000000e+00,  0.00000000e+00,
        3.22760854e+00,  9.61509967e+00,  1.87895827e+00,  0.00000000e+00,
        6.73512959e-01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  4.71061630e+00,  0.00000000e+00,
        1.74068991e+01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00, -8.84677447e-01, -1.81193230e+01,  4.20097810e+00,
        1.92009044e+01,  2.95354144e+00,  0.00000000e+00, -2.14194159e+00,
       -6.70058619e-01,  5.06871956e+00,  3.95499850e-01, -1.62180077e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  3.52469305e+00,  0.00000000e+00,
        1.47941067e+00,  2.47524369e+01,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00, -1.40408671e+01,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  2.24636509e+01,  7.78435795e+00,  0.00000000e+00,
        6.65733490e+00,  2.27013882e+00,  6.22637266e+00,  0.00000000e+00,
        0.00000000e+00, -6.59497116e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  2.93172269e+00, -2.15639242e+00,
        7.05784389e+00,  0.00000000e+00,  0.00000000e+00, -5.18641245e+00,
       -1.99216171e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00, -1.91959559e+01,  0.00000000e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,
        2.43910663e+00,  4.03781726e+00, -3.23639256e+00,  0.00000000e+00,
        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]), 'entropy_': 5.362313539811481, 'alpha_': -0.1447874982382673}
/////////////////////////////
/////////////////////////////
{'beta_categorical': 1.0, 'beta_hinge': 1.0, 'beta_lqp': 1.0, 'beta_multiplier': 1.5, 'beta_threshold': 1.0, 'clamp': True, 'class_weights': 100, 'convergence_tolerance': 2e-06, 'feature_types': ['linear', 'hinge', 'product'], 'n_cpus': 2, 'n_hinge_features': 10, 'n_lambdas': 100, 'n_threshold_features': 10, 'scorer': 'roc_auc', 'tau': 0.5, 'transform': 'cloglog', 'use_lambdas': 'best', 'use_sklearn': True}
checkerboard AUC score: 0.918
checkerboard Sensitivity: 0.757
checkerboard Specificity: 0.940
{'feature_types': ['linear', 'hinge', 'product'], 'tau': 0.5, 'transform': 'cloglog', 'clamp': True, 'scorer': 'roc_auc', 'beta_multiplier': 1.5, 'beta_hinge': 1.0, 'beta_lqp': 1.0, 'beta_threshold': 1.0, 'beta_categorical': 1.0, 'n_hinge_features': 10, 'n_threshold_features': 10, 'convergence_tolerance': 2e-06, 'n_cpus': 2, 'use_lambdas': 'best', 'n_lambdas': 100, 'class_weights': 100, 'use_sklearn': True, 'initialized_': True, 'estimator': LogisticRegression(C=2.574433833577736, penalty='l1', solver='liblinear',
                   tol=2e-06), 'preprocessor': None, 'transformer': MaxentFeatureTransformer(), 'regularization_': None, 'lambdas_': None, 'beta_scores_': array([  0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,  -0.34865352,
         0.        ,  14.88179541,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   7.42726755,
         7.6648967 ,   0.        ,  -4.03696576,   0.        ,
         0.        ,   0.        ,   6.22227603,   0.        ,
         0.        ,   6.20744911,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
        -9.47287254,   0.        ,   0.        ,   0.        ,
         0.        ,   4.72162648,   2.24937829,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,  -3.04607393,
        -8.3017983 ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
        -5.26804948,  -6.27416956,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,  -1.54683736,
        -1.96415083,  -0.04889302,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        , -11.88643145,  -5.78181892,   3.53201786,
         7.69154228,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,  -9.06999988,   0.        ,   0.        ,
        -6.04953769,   0.        ,   0.        ,   0.        ,
         0.        ,   0.95199713,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   5.23063022,   0.        ,
         0.39564332,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        , -10.89540508,   0.        ,
         8.05157053,  15.00647376,   0.        ,  -3.05112708,
         0.        ,   0.        ,   2.33980343,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   2.76665669,   0.        ,
         0.        ,   5.47028069,   0.        ,   0.        ,
         0.        ,   0.        , -13.58352699,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   1.2677573 ,
         8.52202767,  17.54298471,   6.96726384,   1.32627785,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   2.19610532,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,  -0.39668954,
         6.54994733,   0.        ,   0.        ,  -1.65574719,
        -2.68864395,  -0.15671912,  -0.30544528,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         0.        , -10.58791012,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ,
         1.18002148,   0.        ,   0.        ,   0.        ,
         0.        ,   0.        ,   0.        ,   0.        ]), 'entropy_': 4.800719954014083, 'alpha_': 0.8535595307236458}
